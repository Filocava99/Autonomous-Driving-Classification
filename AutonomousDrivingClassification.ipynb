{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Filocava99/Autonomous-Driving-Classification/blob/main/AutonomousDrivingClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNox_iGmXNkt"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEZYI3H5XN3u"
      },
      "source": [
        "!pip install Augmentor\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import Augmentor\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "from tensorflow import keras as K\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4jO92ZLW97l"
      },
      "source": [
        "## Download training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQC1udYsxnS"
      },
      "source": [
        "!wget http://bias.csr.unibo.it/VR/Challenge/AutonomousDriving/train.zip\n",
        "!unzip /content/train.zip\n",
        "!rm /content/train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation"
      ],
      "metadata": {
        "id": "7I51JiYb2-yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentPath(path, label):\n",
        "  basePath = path + \"/\" + label\n",
        "  if os.path.exists(basePath + \"/output\"):\n",
        "    print(\"Deleting \" + basePath + \"/output\")\n",
        "    shutil.rmtree(basePath + \"/output\")\n",
        "  p1 = Augmentor.Pipeline(basePath, save_format=\"PNG\")\n",
        "  p1.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "  p1.skew_tilt(0.4, 0.35)\n",
        "  p1.random_distortion(0.05, 64, 64, 1)\n",
        "  p1.flip_random(0.4)\n",
        "  p1.shear(0.2, max_shear_left=5, max_shear_right=5)\n",
        "  p1.sample(5000)\n",
        "  shutil.move(basePath + \"/output\", \"/content/train_new/\" + label)\n",
        "if os.path.exists(\"/content/train_new\"):\n",
        "  shutil.rmtree(\"/content/train_new\")\n",
        "for dir in os.listdir(\"/content/train\"):\n",
        "  augmentPath(\"/content/train\", dir)"
      ],
      "metadata": {
        "id": "o_3_wEHv2ZQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Donwload evaluation set"
      ],
      "metadata": {
        "id": "D8saE7Lo7H4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://bias.csr.unibo.it/VR/Challenge/AutonomousDriving/eval.zip\n",
        "!unzip /content/eval.zip\n",
        "!rm /content/eval.zip"
      ],
      "metadata": {
        "id": "flFKw6s42-QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtseUfN9LlGP"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRAUSNuRLmSG"
      },
      "source": [
        "def load_data(data_folder_path):\n",
        "    image_list=[]\n",
        "    label_list=[]\n",
        "    class_folder_path_list=glob.glob(data_folder_path+'/*/')\n",
        "    for class_folder_path in class_folder_path_list:\n",
        "        class_folder_path=class_folder_path.replace('\\\\','/')\n",
        "        folder_label=os.path.basename(class_folder_path[:-1])\n",
        "\n",
        "        for image_file_path in glob.glob(class_folder_path+'/*.PNG'):\n",
        "            image_file_path=image_file_path.replace('\\\\','/')\n",
        "            image=Image.open(image_file_path)\n",
        "            image_list.append(np.asarray(image)[:,:,:3])\n",
        "            label_list.append(int(folder_label))\n",
        "    return np.asarray(image_list),np.asarray(label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf4Db77XWGKX"
      },
      "source": [
        "## Loads training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JmxQPFOsRd1"
      },
      "source": [
        "db_path = '/content/train_new/'\n",
        "class_names=['Pedestrian','Cyclist','Car','Truck','Tram','Tricycle']\n",
        "\n",
        "X,y = load_data(db_path)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(X, y,\n",
        "                                                    stratify=y, \n",
        "                                                    test_size=0.25)\n",
        "\n",
        "print('Shape training set: {}'.format(train_x.shape))\n",
        "print('Shape validation set: {}'.format(val_x.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc2bVpxYWlyn"
      },
      "source": [
        "## Images visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSLM2mpvWokP"
      },
      "source": [
        "_, axs = plt.subplots(1, len(class_names),figsize=(20, 10))\n",
        "for i in range(len(class_names)):\n",
        "  train_class_pos=np.where(train_y==i)\n",
        "  rnd_idx=random.randint(0,len(train_class_pos[0]))\n",
        "  p=train_class_pos[0][rnd_idx]\n",
        "  axs[i].imshow(train_x[p]),axs[i].axis('off'),axs[i].set_title(class_names[train_y[p]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loads evaluation set"
      ],
      "metadata": {
        "id": "yWWzTdwI7KjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImages(path):\n",
        "  image_list=[]\n",
        "  image_names=[]\n",
        "  for filename in os.listdir(path):\n",
        "    image_names.append(filename)\n",
        "    image=Image.open(path+\"/\"+filename)\n",
        "    image_list.append(np.asarray(image)[:,:,:3])\n",
        "  return np.asarray(image_list), np.asarray(image_names)\n",
        "\n",
        "db_path = '/content/eval/'\n",
        "test_x, test_names = loadImages(db_path)\n",
        "print(test_names[0])\n",
        "print('Shape training set: {}'.format(test_x.shape))"
      ],
      "metadata": {
        "id": "LBNcZ-sA1rf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation set images visualization"
      ],
      "metadata": {
        "id": "4mOHAuhJ7NGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, axs = plt.subplots(1, 6,figsize=(20, 10))\n",
        "for i in range(6):\n",
        "  axs[i].imshow(test_x[i]),axs[i].axis('off'),axs[i].set_title(test_names[i])"
      ],
      "metadata": {
        "id": "tTZiOcHS2Nd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 import\n",
        "The fully connected layer at the end is removed. All the other layers will be freezed to avoid being trained again, except for the last twenty layers."
      ],
      "metadata": {
        "id": "RUA-gWW67Py7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports ResNet50."
      ],
      "metadata": {
        "id": "aujJUKJ21ZUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "input_t = keras.Input(shape=(224,224,3))\n",
        "res_model = keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor=input_t)"
      ],
      "metadata": {
        "id": "SD15lTvRddek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezes the layers."
      ],
      "metadata": {
        "id": "iS3Y9-sz1U0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in res_model.layers[:143]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "2HwMjqQ3dzBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifies that the layers are correctly freezed."
      ],
      "metadata": {
        "id": "AEhlgwXW1Qmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(res_model.layers):\n",
        "  print(i, layer.name, \"-\", layer.trainable)"
      ],
      "metadata": {
        "id": "W_3VOuTId6Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adds new layers to the model and then starts the training."
      ],
      "metadata": {
        "id": "ciErvIcT780f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = K.models.Sequential()\n",
        "model.add(K.layers.Lambda(lambda x: tf.image.resize(x, (224, 224))))\n",
        "model.add(res_model)\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(256, activation='relu'))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(128, activation='relu'))\n",
        "model.add(K.layers.Dropout(0.3))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(64, activation='relu'))\n",
        "model.add(K.layers.Dropout(0.3))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(6, activation='softmax'))\n",
        "model.compile(loss=losses.sparse_categorical_crossentropy,\n",
        "              optimizer=K.optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpointer = K.callbacks.ModelCheckpoint(filepath='trained-model2.h5',\n",
        "                                           monitor=\"val_accuracy\",\n",
        "                                           verbose=1, save_best_only=True)\n",
        "history = model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=64, epochs=10, verbose=1,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[checkpointer])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "X49CGM7oetqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizes convergence trend (accuracy of training and evaluation sets)."
      ],
      "metadata": {
        "id": "G6IkpDpR8Kzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
        "axs[0].plot(history.history['loss'])\n",
        "axs[0].plot(history.history['val_loss'])\n",
        "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
        "axs[0].set_xlabel('Epochs')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].legend(['Train','Val'])\n",
        "axs[1].plot(history.history['accuracy'])\n",
        "axs[1].plot(history.history['val_accuracy'])\n",
        "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
        "axs[1].set_xlabel('Epochs')\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].legend(['Train', 'Val'])"
      ],
      "metadata": {
        "id": "l29A92Hf6xyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions on the test set"
      ],
      "metadata": {
        "id": "1kkHeFzy8Z0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(test_x)"
      ],
      "metadata": {
        "id": "p1ycuC33zNqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}